{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6743a0-fff9-4ac7-a5f9-881bd6e7043d",
   "metadata": {},
   "source": [
    "###  Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d909d88-5354-4ee8-aae1-808a2fdbf54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (418, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ID             418 non-null    int64  \n",
      " 1   N_Days         418 non-null    int64  \n",
      " 2   Status         418 non-null    object \n",
      " 3   Drug           312 non-null    object \n",
      " 4   Age            418 non-null    int64  \n",
      " 5   Sex            418 non-null    object \n",
      " 6   Ascites        312 non-null    object \n",
      " 7   Hepatomegaly   312 non-null    object \n",
      " 8   Spiders        312 non-null    object \n",
      " 9   Edema          418 non-null    object \n",
      " 10  Bilirubin      418 non-null    float64\n",
      " 11  Cholesterol    284 non-null    float64\n",
      " 12  Albumin        418 non-null    float64\n",
      " 13  Copper         310 non-null    float64\n",
      " 14  Alk_Phos       312 non-null    float64\n",
      " 15  SGOT           312 non-null    float64\n",
      " 16  Tryglicerides  282 non-null    float64\n",
      " 17  Platelets      407 non-null    float64\n",
      " 18  Prothrombin    416 non-null    float64\n",
      " 19  Stage          412 non-null    float64\n",
      "dtypes: float64(10), int64(3), object(7)\n",
      "memory usage: 65.4+ KB\n",
      "\n",
      "Data Types and non-null counts: None\n",
      "\n",
      "Numeric summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>418.0</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>120.810458</td>\n",
       "      <td>1.00</td>\n",
       "      <td>105.2500</td>\n",
       "      <td>209.50</td>\n",
       "      <td>313.75</td>\n",
       "      <td>418.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Days</th>\n",
       "      <td>418.0</td>\n",
       "      <td>1917.782297</td>\n",
       "      <td>1104.672992</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1092.7500</td>\n",
       "      <td>1730.00</td>\n",
       "      <td>2613.50</td>\n",
       "      <td>4795.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>418.0</td>\n",
       "      <td>18533.351675</td>\n",
       "      <td>3815.845055</td>\n",
       "      <td>9598.00</td>\n",
       "      <td>15644.5000</td>\n",
       "      <td>18628.00</td>\n",
       "      <td>21272.50</td>\n",
       "      <td>28650.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.220813</td>\n",
       "      <td>4.407506</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>284.0</td>\n",
       "      <td>369.510563</td>\n",
       "      <td>231.944545</td>\n",
       "      <td>120.00</td>\n",
       "      <td>249.5000</td>\n",
       "      <td>309.50</td>\n",
       "      <td>400.00</td>\n",
       "      <td>1775.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.497440</td>\n",
       "      <td>0.424972</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.2425</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Copper</th>\n",
       "      <td>310.0</td>\n",
       "      <td>97.648387</td>\n",
       "      <td>85.613920</td>\n",
       "      <td>4.00</td>\n",
       "      <td>41.2500</td>\n",
       "      <td>73.00</td>\n",
       "      <td>123.00</td>\n",
       "      <td>588.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alk_Phos</th>\n",
       "      <td>312.0</td>\n",
       "      <td>1982.655769</td>\n",
       "      <td>2140.388824</td>\n",
       "      <td>289.00</td>\n",
       "      <td>871.5000</td>\n",
       "      <td>1259.00</td>\n",
       "      <td>1980.00</td>\n",
       "      <td>13862.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT</th>\n",
       "      <td>312.0</td>\n",
       "      <td>122.556346</td>\n",
       "      <td>56.699525</td>\n",
       "      <td>26.35</td>\n",
       "      <td>80.6000</td>\n",
       "      <td>114.70</td>\n",
       "      <td>151.90</td>\n",
       "      <td>457.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tryglicerides</th>\n",
       "      <td>282.0</td>\n",
       "      <td>124.702128</td>\n",
       "      <td>65.148639</td>\n",
       "      <td>33.00</td>\n",
       "      <td>84.2500</td>\n",
       "      <td>108.00</td>\n",
       "      <td>151.00</td>\n",
       "      <td>598.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelets</th>\n",
       "      <td>407.0</td>\n",
       "      <td>257.024570</td>\n",
       "      <td>98.325585</td>\n",
       "      <td>62.00</td>\n",
       "      <td>188.5000</td>\n",
       "      <td>251.00</td>\n",
       "      <td>318.00</td>\n",
       "      <td>721.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prothrombin</th>\n",
       "      <td>416.0</td>\n",
       "      <td>10.731731</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.60</td>\n",
       "      <td>11.10</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stage</th>\n",
       "      <td>412.0</td>\n",
       "      <td>3.024272</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean          std      min         25%  \\\n",
       "ID             418.0    209.500000   120.810458     1.00    105.2500   \n",
       "N_Days         418.0   1917.782297  1104.672992    41.00   1092.7500   \n",
       "Age            418.0  18533.351675  3815.845055  9598.00  15644.5000   \n",
       "Bilirubin      418.0      3.220813     4.407506     0.30      0.8000   \n",
       "Cholesterol    284.0    369.510563   231.944545   120.00    249.5000   \n",
       "Albumin        418.0      3.497440     0.424972     1.96      3.2425   \n",
       "Copper         310.0     97.648387    85.613920     4.00     41.2500   \n",
       "Alk_Phos       312.0   1982.655769  2140.388824   289.00    871.5000   \n",
       "SGOT           312.0    122.556346    56.699525    26.35     80.6000   \n",
       "Tryglicerides  282.0    124.702128    65.148639    33.00     84.2500   \n",
       "Platelets      407.0    257.024570    98.325585    62.00    188.5000   \n",
       "Prothrombin    416.0     10.731731     1.022000     9.00     10.0000   \n",
       "Stage          412.0      3.024272     0.882042     1.00      2.0000   \n",
       "\n",
       "                    50%       75%       max  \n",
       "ID               209.50    313.75    418.00  \n",
       "N_Days          1730.00   2613.50   4795.00  \n",
       "Age            18628.00  21272.50  28650.00  \n",
       "Bilirubin          1.40      3.40     28.00  \n",
       "Cholesterol      309.50    400.00   1775.00  \n",
       "Albumin            3.53      3.77      4.64  \n",
       "Copper            73.00    123.00    588.00  \n",
       "Alk_Phos        1259.00   1980.00  13862.40  \n",
       "SGOT             114.70    151.90    457.25  \n",
       "Tryglicerides    108.00    151.00    598.00  \n",
       "Platelets        251.00    318.00    721.00  \n",
       "Prothrombin       10.60     11.10     18.00  \n",
       "Stage              3.00      4.00      4.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing value counts:\n",
      "ID                 0\n",
      "N_Days             0\n",
      "Status             0\n",
      "Drug             106\n",
      "Age                0\n",
      "Sex                0\n",
      "Ascites          106\n",
      "Hepatomegaly     106\n",
      "Spiders          106\n",
      "Edema              0\n",
      "Bilirubin          0\n",
      "Cholesterol      134\n",
      "Albumin            0\n",
      "Copper           108\n",
      "Alk_Phos         106\n",
      "SGOT             106\n",
      "Tryglicerides    136\n",
      "Platelets         11\n",
      "Prothrombin        2\n",
      "Stage              6\n",
      "dtype: int64\n",
      "\n",
      "Numerical colums: Index(['ID', 'N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper',\n",
      "       'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin',\n",
      "       'Stage'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical columns: Index(['Status', 'Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema'], dtype='object')\n",
      "\n",
      "-- Status --\n",
      "Status\n",
      "C     232\n",
      "D     161\n",
      "CL     25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Drug --\n",
      "Drug\n",
      "D-penicillamine    158\n",
      "Placebo            154\n",
      "NaN                106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Sex --\n",
      "Sex\n",
      "F    374\n",
      "M     44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Ascites --\n",
      "Ascites\n",
      "N      288\n",
      "NaN    106\n",
      "Y       24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Hepatomegaly --\n",
      "Hepatomegaly\n",
      "Y      160\n",
      "N      152\n",
      "NaN    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Spiders --\n",
      "Spiders\n",
      "N      222\n",
      "NaN    106\n",
      "Y       90\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Edema --\n",
      "Edema\n",
      "N    354\n",
      "S     44\n",
      "Y     20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load the data\n",
    "df = pd.read_csv(\"cirrhosis.csv\")\n",
    "\n",
    "print(\"Shape\",df.shape)\n",
    "#print(df.head())\n",
    "print(\"\\nData Types and non-null counts:\",df.info())\n",
    "print(\"\\nNumeric summary statistics:\")\n",
    "display(df.describe().T)\n",
    "\n",
    "print(\"\\nMissing value counts:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Identify numeric columns\n",
    "num_cols = df.select_dtypes(include=['float64','int64']).columns\n",
    "print(\"\\nNumerical colums:\",num_cols)\n",
    "#Identify categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns\n",
    "print(\"\\nCategorical columns:\",cat_cols)\n",
    "\n",
    "#value counts for each categorical column\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n-- {col} --\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "\n",
    "#Check duplicates\n",
    "print(\"\\nDuplicate rows:\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4166f228-a172-4490-8904-cd0d05f52767",
   "metadata": {},
   "source": [
    "###  Missing value handle\n",
    "\n",
    "    During the exploratory data analysis, I observed that the features\n",
    "    [Drug, Ascites, Hepatomegaly, Spiders, Cholesterol, Copper, Alk_Phos, SGOT, Triglycerides]\n",
    "    had 106 missing values simultaneously from row [313] to [418], corresponding to ~25% of the dataset.\n",
    "\n",
    "    Since those 9 features are missing simultaneously for the same 106 patients, that means it’s not random noise but a systematic missingness.\n",
    "\n",
    "    Since imputing such a large block of missing values (9 features together) could introduce bias and noise, I chose to remove those 106 rows. This ensures that the dataset remains consistent and reliable for model development, even though it reduces the sample size.\n",
    "\n",
    "    After removal, the dataset size reduced from 418 -> 312 patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7316eb3e-1b2c-4b49-a819-ec412ec31366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 418\n",
      "Rows after dropping: 312\n",
      "   ID  N_Days Status             Drug        Age Sex Ascites Hepatomegaly  \\\n",
      "0   1     400      D  D-penicillamine  58.805479   F       Y            Y   \n",
      "1   2    4500      C  D-penicillamine  56.484932   F       N            Y   \n",
      "2   3    1012      D  D-penicillamine  70.120548   M       N            N   \n",
      "3   4    1925      D  D-penicillamine  54.778082   F       N            Y   \n",
      "4   5    1504     CL          Placebo  38.131507   F       N            Y   \n",
      "\n",
      "  Spiders Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
      "0       Y     Y       14.5        261.0     2.60   156.0    1718.0  137.95   \n",
      "1       Y     N        1.1        302.0     4.14    54.0    7394.8  113.52   \n",
      "2       N     S        1.4        176.0     3.48   210.0     516.0   96.10   \n",
      "3       Y     S        1.8        244.0     2.54    64.0    6121.8   60.63   \n",
      "4       Y     N        3.4        279.0     3.53   143.0     671.0  113.15   \n",
      "\n",
      "   Tryglicerides  Platelets  Prothrombin  Stage  \n",
      "0          172.0      190.0         12.2    4.0  \n",
      "1           88.0      221.0         10.6    3.0  \n",
      "2           55.0      151.0         12.0    4.0  \n",
      "3           92.0      183.0         10.3    4.0  \n",
      "4           72.0      136.0         10.9    3.0  \n",
      "ID               0\n",
      "N_Days           0\n",
      "Age              0\n",
      "Bilirubin        0\n",
      "Cholesterol      0\n",
      "Albumin          0\n",
      "Copper           0\n",
      "Alk_Phos         0\n",
      "SGOT             0\n",
      "Tryglicerides    0\n",
      "Platelets        0\n",
      "Prothrombin      0\n",
      "Stage            0\n",
      "dtype: int64\n",
      "Index(['Status', 'Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema'], dtype='object')\n",
      "ID               0\n",
      "N_Days           0\n",
      "Age              0\n",
      "Bilirubin        0\n",
      "Cholesterol      0\n",
      "Albumin          0\n",
      "Copper           0\n",
      "Alk_Phos         0\n",
      "SGOT             0\n",
      "Tryglicerides    0\n",
      "Platelets        0\n",
      "Prothrombin      0\n",
      "Stage            0\n",
      "dtype: int64\n",
      "Status          0\n",
      "Drug            0\n",
      "Sex             0\n",
      "Ascites         0\n",
      "Hepatomegaly    0\n",
      "Spiders         0\n",
      "Edema           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### drop simultaneous empty values\n",
    "rows_to_drop = ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders', 'Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides']\n",
    "\n",
    "df_all = df.copy()\n",
    "\n",
    "# Drop rows where ALL of these columns are null simultaneously\n",
    "df = df[~df[rows_to_drop].isnull().all(axis=1)]\n",
    "\n",
    "print(f\"Rows before dropping: {len(df_all)}\")\n",
    "print(f\"Rows after dropping: {len(df)}\")\n",
    "\n",
    "###age is converted to year\n",
    "df['Age'] = df['Age'] / 365\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df = df.copy()\n",
    "#Numeric missing value handling\n",
    "for col in num_cols:\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    if missing_count>0:\n",
    "        skewness = df[col].skew()\n",
    "        if abs(skewness) < 0.5:\n",
    "            df.loc[:, col] = df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            df.loc[:, col] = df[col].fillna(df[col].median())\n",
    "\n",
    "#check if missing value remain\n",
    "print(df[num_cols].isnull().sum())\n",
    "\n",
    "print(cat_cols)\n",
    "#cat col missing value handling\n",
    "for col in cat_cols:\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    if missing_count>0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(df[num_cols].isnull().sum())\n",
    "print(df[cat_cols].isnull().sum())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e2055-fa2e-4501-a905-1d6d141f88f9",
   "metadata": {},
   "source": [
    "###  Split the data set into training and test set with a ratio of  (8:2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690d725f-f5aa-494c-97b6-67604d0d640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Empty Status:  0\n",
      "After Mapping:  Status\n",
      "1    168\n",
      "0    125\n",
      "2     19\n",
      "Name: count, dtype: int64\n",
      "Train set class distribution:\n",
      " Status\n",
      "1    0.538153\n",
      "0    0.401606\n",
      "2    0.060241\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      " Status\n",
      "1    0.539683\n",
      "0    0.396825\n",
      "2    0.063492\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Check Empty Status: \",df['Status'].isnull().sum())\n",
    "#Map status \n",
    "status_map = {'D':0, 'C':1, 'CL':2}\n",
    "df['Status'] = df['Status'].map(status_map)\n",
    "\n",
    "print(\"After Mapping: \",df['Status'].value_counts())\n",
    "\n",
    "X = df.drop(columns=['ID','Status'], axis=1)\n",
    "y = df['Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=7, stratify=y)\n",
    "\n",
    "print(\"Train set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2403471-1cc0-4995-8d63-185cd8ff462a",
   "metadata": {},
   "source": [
    "###  Show the feature types and indicate which features are continuous or categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27774777-0ed8-4c57-ab31-86061730c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (249, 18)\n",
      "Test shape: (63, 18)\n",
      "\n",
      "Numerical features (continuous): ['N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n",
      "Categorical features: ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify feature types in training data\n",
    "num_cols_train = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols_train = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "print(\"\\nNumerical features (continuous):\", list(num_cols_train))\n",
    "print(\"Categorical features:\", list(cat_cols_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ce8f8-0e11-4c47-9582-6dde9dac53e2",
   "metadata": {},
   "source": [
    "###  Necessary encoding for the categorical features. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4c9c59-9ecb-4639-822e-e5176d351dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after missing value handling: (249, 18)\n",
      "Shape after Encoding: (249, 24)\n",
      "\n",
      " X Test (63, 24)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 249 entries, 29 to 144\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   N_Days                249 non-null    int64  \n",
      " 1   Age                   249 non-null    float64\n",
      " 2   Sex                   249 non-null    int64  \n",
      " 3   Bilirubin             249 non-null    float64\n",
      " 4   Cholesterol           249 non-null    float64\n",
      " 5   Albumin               249 non-null    float64\n",
      " 6   Copper                249 non-null    float64\n",
      " 7   Alk_Phos              249 non-null    float64\n",
      " 8   SGOT                  249 non-null    float64\n",
      " 9   Tryglicerides         249 non-null    float64\n",
      " 10  Platelets             249 non-null    float64\n",
      " 11  Prothrombin           249 non-null    float64\n",
      " 12  Stage                 249 non-null    float64\n",
      " 13  Drug_D-penicillamine  249 non-null    bool   \n",
      " 14  Drug_Placebo          249 non-null    bool   \n",
      " 15  Ascites_N             249 non-null    bool   \n",
      " 16  Ascites_Y             249 non-null    bool   \n",
      " 17  Hepatomegaly_N        249 non-null    bool   \n",
      " 18  Hepatomegaly_Y        249 non-null    bool   \n",
      " 19  Spiders_N             249 non-null    bool   \n",
      " 20  Spiders_Y             249 non-null    bool   \n",
      " 21  Edema_N               249 non-null    bool   \n",
      " 22  Edema_S               249 non-null    bool   \n",
      " 23  Edema_Y               249 non-null    bool   \n",
      "dtypes: bool(11), float64(11), int64(2)\n",
      "memory usage: 29.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "print(\"Shape after missing value handling:\",X_train.shape)\n",
    "\n",
    "X_train_encode = X_train.copy()\n",
    "X_test_encode = X_test.copy()\n",
    "\n",
    "#label encoder\n",
    "le = LabelEncoder()\n",
    "X_train_encode['Sex'] = le.fit_transform(X_train_encode['Sex'])\n",
    "X_test_encode['Sex'] = le.transform(X_test_encode['Sex'])\n",
    "\n",
    "#One hot encoder\n",
    "cat_col_rest = [col for col in X_train_encode.select_dtypes(include=['object','category']).columns if col != 'Sex']\n",
    "\n",
    "X_train_encode = pd.get_dummies(X_train_encode,columns=cat_col_rest,drop_first=False)\n",
    "X_test_encode = pd.get_dummies(X_test_encode,columns=cat_col_rest,drop_first=False)\n",
    "\n",
    "X_train_encode,X_test_encode = X_train_encode.align(X_test_encode, join='left',axis=1,fill_value=0)\n",
    "\n",
    "print(\"Shape after Encoding:\",X_train_encode.shape) \n",
    "print(\"\\n X Test\",X_test_encode.shape)\n",
    "print(X_train_encode.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73694b3-edef-453a-b12a-175092b3ccb7",
   "metadata": {},
   "source": [
    "###  Show the label distribution based on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d298a350-78ce-431e-bfb7-e260e239f822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:0,C:1,CL:2\n",
      "Status\n",
      "1    134\n",
      "0    100\n",
      "2     15\n",
      "Name: count, dtype: int64\n",
      "Status\n",
      "1    53.815261\n",
      "0    40.160643\n",
      "2     6.024096\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training set is imbalanced.\n"
     ]
    }
   ],
   "source": [
    "# Show label counts\n",
    "label_counts = y_train.value_counts()\n",
    "print(\"D:0,C:1,CL:2\")\n",
    "print(label_counts)\n",
    "\n",
    "# Show label percentages\n",
    "label_percentages = y_train.value_counts(normalize=True) * 100\n",
    "print(label_percentages)\n",
    "\n",
    "#  visualize with a bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,2))\n",
    "bars = plt.bar(label_counts.index.astype(str), label_counts.values)\n",
    "plt.title('Training Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate counts on top of bars\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, \n",
    "             bar.get_height() + 5, \n",
    "             str(bar.get_height()), \n",
    "             ha='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Explicit check for imbalance\n",
    "if label_percentages.max() - label_percentages.min() > 20:\n",
    "    print(\" The training set is imbalanced.\")\n",
    "else:\n",
    "    print(\" The training set is relatively balanced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb1a43-1ff7-442e-930e-d755b6cb984a",
   "metadata": {},
   "source": [
    "    The training set is not balanced.\n",
    "\n",
    "    The dataset has three classes with the following proportions:\n",
    "    Class 0: 40.16%\n",
    "    Class 1: 53.82%\n",
    "    Class 2: 6.02%\n",
    "    There is a large difference between the most frequent class (class 1, 53.82%) and the least frequent class (class 2, 6.02%).\n",
    "\n",
    "    Since the difference in class proportions (≈48%) is much higher than a reasonable threshold for balance (often around 20%), this indicates that the dataset is imbalanced, with class 2 being significantly underrepresented.\n",
    "\n",
    "    This imbalance can affect model training, causing the model to favor the majority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a2676-3f79-4292-b3a8-2afe656a82b2",
   "metadata": {},
   "source": [
    "### Create three supervised machine learning (ML) models for predicting “Status.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65562bf2-5d0f-4107-b792-157c6c343deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Train F1 = 0.712 | Mean F1-score = 0.527 | Std = 0.076\n",
      "      Random Forest: Train F1 = 1.000 | Mean F1-score = 0.515 | Std = 0.032\n",
      "                SVM: Train F1 = 0.588 | Mean F1-score = 0.503 | Std = 0.034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# X_train_encode, X_test_encode, y_train, y_test\n",
    "###Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_encode_scale = scaler.fit_transform(X_train_encode)  \n",
    "X_test_encode_scale = scaler.transform(X_test_encode)  \n",
    "\n",
    "#Stratified K-Fold setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "\n",
    "# Macro average = treats all classes equally\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "### Model definitions\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),  \n",
    "    \"      Random Forest\": RandomForestClassifier(random_state=7),\n",
    "    \"                SVM\":SVC(kernel='rbf',probability=True,random_state=7)\n",
    "}   \n",
    "###scores = cross_val_score(model, X_train_encode, y_train, cv=skf, scoring=f1_scorer)\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_train_encode_scale, y_train, cv=skf, scoring=f1_scorer, return_train_score=True)\n",
    "    results[name] = {\n",
    "        \"Train F1\": cv_results['train_score'].mean(),\n",
    "        \"Val F1\": cv_results['test_score'].mean(),\n",
    "        \"Std\": cv_results['test_score'].std()\n",
    "    }\n",
    "\n",
    "for name, scores in results.items():\n",
    "    print(f\"{name}: Train F1 = {scores['Train F1']:.3f} | Mean F1-score = {scores['Val F1']:.3f} | Std = {scores['Std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef49c1a-a85b-4c3b-a672-bd8555a14c5a",
   "metadata": {},
   "source": [
    "### Report Validation method and performance matrix\n",
    "    We used k-fold cross-validation to assess model performance, with the F1-score selected as the evaluation metric due to the imbalanced nature of the dataset. The results are:\n",
    "\n",
    "      Logistic Regression: Train F1 = 0.712 | Mean F1 = 0.527 | Std = 0.076\n",
    "      \n",
    "            Random Forest: Train F1 = 1.000 | Mean F1 = 0.515 | Std = 0.032\n",
    "            \n",
    "                      SVM: Train F1 = 0.588 | Mean F1 = 0.503 | Std = 0.034\n",
    "\n",
    "### Overfitting and Underfitting Analysis\n",
    "    Logistic Regression shows a moderate drop from training to validation scores, indicating mild overfitting but relatively stable generalization.\n",
    "\n",
    "    Random Forest achieves a perfect training score (1.000) but much lower validation performance, indicating severe overfitting—the model has memorized the training data and fails to generalize.\n",
    "\n",
    "    SVM performs similarly on training and validation (both relatively low), suggesting underfitting—the model is too simple (or not tuned) to capture the underlying patterns in the data.\n",
    "    \n",
    "    Overall, Random Forest is the most overfitted, Logistic Regression shows mild overfitting, and SVM appears to be underfitting. This aligns with the principle that models with excessive complexity (Random Forest with deep trees) tend to overfit, while overly simple models (SVM with default parameters) may underfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97577bb-70e6-4f58-b468-f3aafe15828d",
   "metadata": {},
   "source": [
    "###  Justify different design decisions for each ML model.\n",
    "\n",
    "Validation Method:\n",
    "\n",
    "    I used Stratified K-Fold cross-validation (n=5) to ensure that each fold maintained the same class distribution as the full dataset, which is especially important when classes are imbalanced.\n",
    "    The shuffle=True parameter helped avoid any bias from the original ordering of the data.\n",
    "    A fixed random_state=7 ensured reproducibility.\n",
    "\n",
    "Evaluation Metric:\n",
    "\n",
    "    I chose macro-averaged F1-score as the performance metric because it treats all classes equally, making it suitable for imbalanced datasets.\n",
    "    This avoids bias towards the majority class that accuracy could introduce.\n",
    "\n",
    "Model Choices & Hyperparameters:\n",
    "\n",
    "    1. Logistic Regression\n",
    "    \n",
    "        Chosen as a simple, interpretable baseline model for classification tasks.\n",
    "        Used class_weight='balanced' to automatically adjust weights inversely proportional to class frequencies, improving performance on imbalanced data.\n",
    "        Increased max_iter=1000 to ensure convergence during training.\n",
    "\n",
    "    2. Random Forest Classifier\n",
    "\n",
    "        Selected for its ability to capture nonlinear relationships and feature interactions without the need for feature scaling.\n",
    "        It is robust to outliers and resistant to overfitting when tuned appropriately.\n",
    "        A fixed random_state=7 ensures reproducible results.\n",
    "\n",
    "    3. Support Vector Machine (SVM)\n",
    "\n",
    "        Chosen for its strength in handling complex, non-linear decision boundaries.\n",
    "        Used the RBF kernel, as it can map features into higher dimensions to separate classes effectively.\n",
    "        Enabled probability=True for probability estimates (e.g., useful for ROC/AUC calculations).\n",
    "        \n",
    "        A fixed random_state=7 was used for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0745042-5757-4a30-be8e-0aec8e169425",
   "metadata": {},
   "source": [
    "###  Optimised hyper-parameters for each ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121e1583-370c-4e41-9f94-8b9ca8ce640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Train F1 Score (best params): 0.716\n",
      "Validation F1 Score (best params): 0.574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Stratified K-Fold setup   -> Already defined\n",
    "# Macro average = treats all classes equally  -> already defined\n",
    "\n",
    "###Logistic Regression\n",
    "log_reg_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1'],\n",
    "    'solver':['liblinear'],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "log_reg = LogisticRegression(max_iter=1000,random_state=7)\n",
    "gridSearchCv_lr = GridSearchCV(log_reg,log_reg_params, scoring=f1_scorer, cv=skf , n_jobs=-1,return_train_score=True)\n",
    "gridSearchCv_lr.fit(X_train_encode_scale,y_train)\n",
    "\n",
    "best_index = gridSearchCv_lr.best_index_\n",
    "train_score = gridSearchCv_lr.cv_results_['mean_train_score'][best_index]\n",
    "val_score = gridSearchCv_lr.best_score_  # same as cv_results_['mean_test_score'][best_index]\n",
    "\n",
    "print(\"Best Logistic Regression Params:\", gridSearchCv_lr.best_params_)\n",
    "print(f\"Train F1 Score (best params): {train_score:.3f}\")\n",
    "print(f\"Validation F1 Score (best params): {val_score:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a1749d-f38c-43f6-a1cb-d47410ac8527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Train F1 Score (best params): 1.000\n",
      "Validation F1 Score (best params): 0.520\n"
     ]
    }
   ],
   "source": [
    "###Random Forest\n",
    "ran_for_params = {\n",
    "    'n_estimators':[100,200,500],\n",
    "    'max_depth':[None,5,10,20],\n",
    "    'min_samples_split':[2,5,10]\n",
    "}\n",
    "ran_for = RandomForestClassifier(random_state=7)\n",
    "gridSearchCv_rf = GridSearchCV(ran_for,ran_for_params,scoring=f1_scorer,cv=skf, n_jobs=-1,\n",
    "    return_train_score=True)\n",
    "gridSearchCv_rf.fit(X_train_encode_scale,y_train)\n",
    "\n",
    "best_index = gridSearchCv_rf.best_index_\n",
    "train_score = gridSearchCv_rf.cv_results_['mean_train_score'][best_index]\n",
    "val_score = gridSearchCv_rf.best_score_\n",
    "\n",
    "print(\"Best Random Forest params:\", gridSearchCv_rf.best_params_)\n",
    "print(f\"Train F1 Score (best params): {train_score:.3f}\")\n",
    "print(f\"Validation F1 Score (best params): {val_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dddd99a-1873-49a4-a7ca-cb02fdcf8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM params: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Train F1 Score (best params): 0.543\n",
      "Validation F1 Score (best params): 0.508\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###SVM\n",
    "svm_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],   \n",
    "    'gamma': ['scale', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "svm = SVC(probability=True,random_state=7)\n",
    "gridSearchCv_svm = GridSearchCV(svm, svm_params,scoring=f1_scorer, cv=skf, n_jobs=-1,\n",
    "    return_train_score=True)\n",
    "gridSearchCv_svm.fit(X_train_encode_scale,y_train)\n",
    "\n",
    "best_index = gridSearchCv_svm.best_index_\n",
    "train_score = gridSearchCv_svm.cv_results_['mean_train_score'][best_index]\n",
    "val_score = gridSearchCv_svm.best_score_\n",
    "\n",
    "print(\"Best SVM params:\", gridSearchCv_svm.best_params_)\n",
    "print(f\"Train F1 Score (best params): {train_score:.3f}\")\n",
    "print(f\"Validation F1 Score (best params): {val_score:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ab51a00-d114-4ed7-8422-4a041064cb7a",
   "metadata": {},
   "source": [
    "### Comparison Before and After Hyperparameter Optimisation\n",
    "\n",
    "     Metric                 | Logistic Regression | Random Forest  | SVM           \n",
    "     ---------------------- | --------------------| ---------------| -------\n",
    "     Train F1 (Before)      | 0.712               | 1.000          | 0.588  \n",
    "    \n",
    "     Validation F1 (Before) | 0.527               | 0.515          | 0.503  \n",
    "    \n",
    "     Train F1 (After)       | 0.716               | 1.000          | 0.543 \n",
    "    \n",
    "     CV F1 (After Tuning)   | 0.574               | 0.520          | 0.508 \n",
    "    \n",
    "\n",
    "    Best Hyperparameters\n",
    "    \n",
    "    Logistic Regression : C=1, class_weight='balanced', penalty='l1',solver='liblinear'\t\n",
    "    \n",
    "    Random Forest : max_depth=10, min_samples_split=2\n",
    "    \n",
    "    SVM : n_estimators=500\tC=1, gamma=0.01, kernel='rbf'\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "    Logistic Regression:\n",
    "    Before tuning, the model showed a noticeable gap between training (0.712) and validation F1 (0.527), suggesting mild overfitting. After hyperparameter tuning, the validation F1 improved to 0.574, while the training F1 slightly increased to 0.716. This indicates better generalisation with effective regularisation and class weight balancing, helping to reduce overfitting and improve model robustness.\n",
    "    \n",
    "    Random Forest:\n",
    "    Initially, the model had a perfect training F1 score (1.0) but a lower validation F1 (0.515), indicating strong overfitting. After tuning, the validation F1 improved marginally to 0.520, while the training F1 remained at 1.0. This suggests that although hyperparameter tuning (e.g., limiting tree depth) helped slightly, the model still overfits the training data.\n",
    "    \n",
    "    SVM:\n",
    "    Before tuning, the training and validation F1 scores were 0.588 and 0.503 respectively, with a relatively small gap, suggesting slight underfitting. After tuning, the validation score improved slightly to 0.508, but the training F1 decreased to 0.543, implying the model might have become simpler with better regularisation, resulting in modest improvements in generalisation.\n",
    "    \n",
    "    Hyperparameter optimisation improved model performance across all three classifiers, especially Logistic Regression, by better managing model complexity and class imbalance. Random Forest showed slight reduction in overfitting, while SVM improved its decision boundary flexibility. This underscores the importance of tuning hyperparameters to enhance predictive performance beyond default settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d11f9c-bdb0-48e2-b855-8535ac6005a4",
   "metadata": {},
   "source": [
    "### Use a method to deal with the label imbalance issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dcb008c-1c3d-4703-92c3-43d17fbed558",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will check it different imbalance handling method (SMOTE, SMOTEENN, ADASYN, etc.) as input, so I built a function\n",
    "\n",
    "def evaluate_imbalance_method(resampler, X_train_scaled, y_train, X_test_scaled, y_test, \n",
    "                              gridsearch_lr, gridsearch_rf, gridsearch_svm):\n",
    "    \"\"\"\n",
    "    resampler: an instance of imblearn resampling method (e.g., SMOTE(), SMOTEENN())\n",
    "    X_train_scaled, y_train: original scaled train data\n",
    "    X_test_scaled, y_test: original scaled test data\n",
    "    gridsearch_lr, gridsearch_rf, gridsearch_svm: pre-defined GridSearchCV objects\n",
    "    \n",
    "    Returns a dictionary with macro F1 scores on test data after balancing.\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning with resampler: {resampler.__class__.__name__}\")\n",
    "    \n",
    "    # Resample training data\n",
    "    X_train_bal, y_train_bal = resampler.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    # Fit models with balanced data\n",
    "    gridsearch_lr.fit(X_train_bal, y_train_bal)\n",
    "    gridsearch_rf.fit(X_train_bal, y_train_bal)\n",
    "    gridsearch_svm.fit(X_train_bal, y_train_bal)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred_lr = gridsearch_lr.predict(X_test_scaled)\n",
    "    y_pred_rf = gridsearch_rf.predict(X_test_scaled)\n",
    "    y_pred_svm = gridsearch_svm.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute macro F1 scores\n",
    "    f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        \"Resampler\": resampler.__class__.__name__,\n",
    "        \"Logistic Regression F1\": f1_lr,\n",
    "        \"Random Forest F1\": f1_rf,\n",
    "        \"SVM F1\": f1_svm,\n",
    "        \"Best LR Params\": gridsearch_lr.best_params_,\n",
    "        \"Best RF Params\": gridsearch_rf.best_params_,\n",
    "        \"Best SVM Params\": gridsearch_svm.best_params_\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c3d853-c79c-4e64-ab12-7a89426735d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running with resampler: SMOTE\n",
      "\n",
      "Running with resampler: SMOTEENN\n",
      "\n",
      "Running with resampler: ADASYN\n",
      "  Resampler  Logistic Regression F1  Random Forest F1    SVM F1  \\\n",
      "0     SMOTE                0.511364          0.536281  0.533937   \n",
      "1  SMOTEENN                0.597534          0.481852  0.422815   \n",
      "2    ADASYN                0.551720          0.496724  0.517280   \n",
      "\n",
      "                                      Best LR Params  \\\n",
      "0  {'C': 0.1, 'class_weight': 'balanced', 'penalt...   \n",
      "1  {'C': 10, 'class_weight': 'balanced', 'penalty...   \n",
      "2  {'C': 10, 'class_weight': 'balanced', 'penalty...   \n",
      "\n",
      "                                      Best RF Params  \\\n",
      "0  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
      "1  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
      "2  {'max_depth': None, 'min_samples_split': 2, 'n...   \n",
      "\n",
      "                             Best SVM Params  \n",
      "0    {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}  \n",
      "1  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}  \n",
      "2  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}  \n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Assuming gridSearchCv_lr, gridSearchCv_rf, gridSearchCv_svm are defined\n",
    "\n",
    "resamplers = [SMOTE(random_state=7), SMOTEENN(random_state=7), ADASYN(random_state=7)]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for resampler in resamplers:\n",
    "    res = evaluate_imbalance_method(resampler, \n",
    "                                   X_train_encode_scale, y_train, \n",
    "                                   X_test_encode_scale, y_test,\n",
    "                                   gridSearchCv_lr, gridSearchCv_rf, gridSearchCv_svm)\n",
    "    all_results.append(res)\n",
    "\n",
    "# Convert to DataFrame for easier comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd6acc-ebf9-4987-87df-5cfcaa4e6260",
   "metadata": {},
   "source": [
    "To address the label imbalance issue in the dataset, I applied SMOTE, SMOTEENN, and ADASYN to the training data. \n",
    "\n",
    "Before the balanced class performance:\n",
    "\n",
    "                  Model\t  Train F1         CV F1  \n",
    "    \n",
    "    Logistic Regression\t     0.716         0.574\t                \n",
    "          Random Forest\t     1.000         0.520\t                   \n",
    "                    SVM\t     0.543         0.508\t           \n",
    "\n",
    "    Best Hyperparameters Before the balanced class:\n",
    "    Logistic Regression: C=1,class_weight='balanced',penalty='l1',solver='liblinear'\n",
    "    Random Forest:       max_depth=10, min_samples_split=2, n_estimators=500\n",
    "    SVM:                 C=1, gamma=0.01, kernel='rbf'\n",
    "                   \n",
    "After training the models on the balanced dataset, I evaluated their performance using the macro-averaged F1-score on the original test set and compared it with the results for the different balancing techniques. The results are summarized below:\n",
    "\n",
    "    Results (Macro F1-score after balancing):\n",
    "\n",
    "    Resampling Method\tLogistic Regression\tRandom Forest\tSVM \n",
    "                SMOTE\t0.511\t                 0.536\t        0.534\n",
    "             SMOTEENN\t0.598\t                 0.482\t        0.423\n",
    "               ADASYN\t0.552\t                 0.497\t        0.517\n",
    "\n",
    "    Best Hyperparameters per Resampler:\n",
    "\n",
    "    Logistic Regression:\n",
    "    \n",
    "        SMOTE ->    C=0.1, class_weight='balanced', penalty='l1', solver='liblinear'\n",
    "        SMOTEENN -> C=10,  class_weight='balanced', penalty='l1', solver='liblinear'\n",
    "        ADASYN ->   C=10,  class_weight='balanced', penalty='l1', solver='liblinear'\n",
    "    \n",
    "    Random Forest:\n",
    "    \n",
    "        All resamplers -> max_depth=None, min_samples_split=2, n_estimators=500\n",
    "    \n",
    "    SVM:\n",
    "    \n",
    "        SMOTE ->    C=1,   gamma=0.1,  kernel='rbf'\n",
    "        SMOTEENN -> C=10,  gamma=0.01, kernel='rbf'\n",
    "        ADASYN ->   C=100, gamma=0.1,  kernel='rbf'\n",
    "\n",
    "    We see the F1 score (0.598) is the highest for Logistic Regression and SMOTEENN-balanced techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f021a6-3976-4e75-8126-3836a53c7898",
   "metadata": {},
   "source": [
    "###  Model recommendation based on the report.\n",
    "\n",
    "    Based on the comprehensive evaluation of various imbalance handling methods and hyperparameter tuning, the Logistic Regression model combined with the SMOTEENN resampling technique is recommended for predicting the survival status of liver cirrhosis patients. This model, with hyperparameters set as C=10, class_weight='balanced', penalty='l1', and solver='liblinear', achieved the highest macro F1 score of 0.598. This performance indicates an effective balance between sensitivity and precision across all survival classes.\n",
    "    \n",
    "    While Random Forest and Support Vector Machine (SVM) models showed competitive results with SMOTE, the Random Forest model exhibited tendencies to overfit, and the SVM model delivered lower overall F1 scores. \n",
    "    \n",
    "    Therefore, Logistic Regression with SMOTEENN provides the best trade-off between model complexity, generalization ability, and predictive accuracy for this task. Additionally, Logistic Regression offers greater interpretability, which is valuable for clinical decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7f9ec-4582-4060-930c-2bc37f61fdb6",
   "metadata": {},
   "source": [
    "###  Prediction on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72673ac6-19c4-41db-889f-093b4ab3f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.730\n",
      "Precision (macro): 0.608\n",
      "Recall (macro): 0.592\n",
      "F1 Score: 0.598\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73        25\n",
      "           1       0.79      0.76      0.78        34\n",
      "           2       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.73        63\n",
      "   macro avg       0.61      0.59      0.60        63\n",
      "weighted avg       0.73      0.73      0.73        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Apply SMOTEENN on already scaled training data\n",
    "sme = SMOTEENN(random_state=7)\n",
    "X_train_bal, y_train_bal = sme.fit_resample(X_train_encode_scale, y_train)\n",
    "\n",
    "# Train Logistic Regression with best hyperparameters\n",
    "best_lr = LogisticRegression(\n",
    "    C=10,\n",
    "    class_weight='balanced',\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    random_state=7\n",
    ")\n",
    "best_lr.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Predict on scaled test data\n",
    "y_pred = best_lr.predict(X_test_encode_scale)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "# Predictions (you already have y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision (macro): {precision:.3f}\")\n",
    "print(f\"Recall (macro): {recall:.3f}\")\n",
    "print(f\"F1 Score: {test_f1:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd42279-c853-4ff3-9ef6-464ca89868f0",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "    Model: Logistic Regression (C=10, penalty=l1, solver=liblinear, class_weight=balanced) with SMOTEENN\n",
    "\n",
    "    Overall performance (test set):\n",
    "            Accuracy: 0.73\n",
    "            Precision (macro): 0.60\n",
    "            Recall (macro): 0.59\n",
    "            F1 Score (macro): 0.59\n",
    "\n",
    "    Per-class results:\n",
    "            Class 0 -> Precision: 0.70, Recall: 0.76, F1: 0.73 (good performance)\n",
    "            Class 1 -> Precision: 0.79, Recall: 0.76, F1: 0.78 (strong performance)\n",
    "            Class 2 -> Precision: 0.33, Recall: 0.25, F1: 0.29 (poor performance, minority class remains difficult)\n",
    "\n",
    "    Interpretation:\n",
    "            Model handles majority classes (0 and 1) well.\n",
    "            Minority class (2) is still underrepresented and not well captured, even with SMOTEENN.\n",
    "            Weighted average F1 (0.73) looks higher due to class imbalance, but macro F1 (0.60) gives a fairer picture.\n",
    "\n",
    "    Fit assessment:\n",
    "            Test scores are close to validation scores -> no severe overfitting.\n",
    "            Low performance on class 2 suggests underfitting for the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ccf4d5-9047-44e7-bd74-2ab0f5b27a56",
   "metadata": {},
   "source": [
    "### Analyse the importance of the features for predicting “Status” using two different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206a3ee7-69b0-486b-afdc-aced6d776209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients per class:\n",
      "     N_Days       Age       Sex  Bilirubin  Cholesterol   Albumin    Copper  \\\n",
      "0  1.787403  7.106679  0.151206   7.792081    -1.596496  0.000000  0.000000   \n",
      "1  0.249762  2.273641 -1.154784  -6.574663    -1.751912  0.000000 -0.258332   \n",
      "2 -2.247433 -5.145708  1.565559  -0.595660    -0.237266  0.046937  0.000000   \n",
      "\n",
      "   Alk_Phos      SGOT  Tryglicerides  ...  Drug_Placebo  Ascites_N  Ascites_Y  \\\n",
      "0  1.532895  8.492951      -0.396492  ...     -0.845803  -0.849655   1.360306   \n",
      "1  0.000000 -4.004657       0.000000  ...      2.516569   0.758961   0.000000   \n",
      "2 -0.460905  1.541243       0.037985  ...      0.114578   0.613707  -0.219756   \n",
      "\n",
      "   Hepatomegaly_N  Hepatomegaly_Y  Spiders_N  Spiders_Y  Edema_N   Edema_S  \\\n",
      "0       -3.514443        4.403318  -0.538269   0.755694      0.0 -2.268372   \n",
      "1        2.742447       -3.511549   0.269717  -0.372206      0.0  0.000000   \n",
      "2       -0.570486        0.784176  -0.156250   0.223299      0.0  0.657785   \n",
      "\n",
      "    Edema_Y  \n",
      "0  0.406660  \n",
      "1 -2.417427  \n",
      "2 -0.717663  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "\n",
      "Top 10 features by average absolute coefficient:\n",
      "Bilirubin         4.987468\n",
      "Age               4.842009\n",
      "SGOT              4.679617\n",
      "Hepatomegaly_Y    2.899681\n",
      "Hepatomegaly_N    2.275792\n",
      "Prothrombin       2.143288\n",
      "N_Days            1.428199\n",
      "Cholesterol       1.195225\n",
      "Edema_Y           1.180583\n",
      "Drug_Placebo      1.158984\n",
      "dtype: float64\n",
      "Age            0.153299\n",
      "Bilirubin      0.123701\n",
      "Prothrombin    0.085700\n",
      "N_Days         0.083699\n",
      "SGOT           0.082068\n",
      "Stage          0.057820\n",
      "Cholesterol    0.056802\n",
      "Copper         0.054799\n",
      "Platelets      0.051463\n",
      "Alk_Phos       0.051010\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - multiclass feature importance\n",
    "coef_df = pd.DataFrame(best_lr.coef_, columns=X_train_encode.columns, index=best_lr.classes_)\n",
    "print(\"Coefficients per class:\")\n",
    "print(coef_df)\n",
    "\n",
    "avg_coef = pd.Series(np.mean(np.abs(best_lr.coef_), axis=0), index=X_train_encode.columns)\n",
    "avg_coef.sort_values(ascending=False, inplace=True)\n",
    "print(\"\\nTop 10 features by average absolute coefficient:\")\n",
    "print(avg_coef.head(10))\n",
    "\n",
    "# Random Forest feature importance\n",
    "importances = gridSearchCv_rf.best_estimator_.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=X_train_encode.columns).sort_values(ascending=False)\n",
    "print(feat_imp.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a5fb6-4081-41d5-9be7-0433c06e979f",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis\n",
    "\n",
    "    To analyze feature importance for predicting the survival status, I employed two complementary approaches: Logistic Regression and Random Forest.  \n",
    "    \n",
    "    Logistic Regression is a linear model; the magnitude of the standardized coefficients indicates the strength and direction of the relationship between each feature and the outcome. For multiclass outcomes, I calculated **average absolute coefficients across classes** to summarize overall importance.  \n",
    "    Random Forest measures feature importance based on the total reduction in node impurity (Gini importance) contributed by each feature across all trees.  \n",
    "\n",
    "        ### Logistic Regression Coefficients (Top 5 Features)\n",
    "\n",
    "        | Feature        | Importance |\n",
    "        |----------------|-----------|\n",
    "        | Bilirubin      | 4.987     |\n",
    "        | Age            | 4.842     |\n",
    "        | SGOT           | 4.680     |\n",
    "        | Hepatomegaly_Y | 2.900     |\n",
    "        | Hepatomegaly_N | 2.276     |\n",
    "\n",
    "    Statistical reasoning: The coefficients measure the linear effect of each feature on the log-odds of predicting each class. Averaging absolute values across classes provides an overall view of feature importance regardless of direction.  \n",
    "\n",
    "        ### Random Forest Feature Importance (Top 5 Features)\n",
    "        \n",
    "        | Feature      | Importance |\n",
    "        |--------------|-----------|\n",
    "        | Age          | 0.153     |\n",
    "        | Bilirubin    | 0.124     |\n",
    "        | Prothrombin  | 0.086     |\n",
    "        | N_Days       | 0.084     |\n",
    "        | SGOT         | 0.082     |\n",
    "\n",
    "    Statistical reasoning: Importances are derived from impurity reduction averaged over many trees, capturing both linear and non-linear contributions.  \n",
    "\n",
    "### Comparison\n",
    "\n",
    "        Overlap: Age, Bilirubin, Prothrombin, SGOT appear as top predictors in both models -> confirms strong predictive power.  \n",
    "        Differences: Logistic Regression emphasizes features with strong linear effects (e.g., SGOT, Hepatomegaly_Y), while Random Forest highlights additional features influenced by non-linear interactions.  \n",
    "        \n",
    "        Conclusion: Age and Bilirubin are consistently strong predictors across both models, while SGOT and Hepatomegaly_Y show strong linear effects captured by logistic regression but less prominently in Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5db35a-3343-4d53-8a2e-e445f29239a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Top 5 Logistic Regression features (average absolute coefficients)\n",
    "top_lr = avg_coef.head(5)\n",
    "\n",
    "# Top 5 Random Forest features\n",
    "top_rf = feat_imp.head(5)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(12,3))\n",
    "\n",
    "# Logistic Regression subplot\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(x=top_lr.values, y=top_lr.index, color=\"steelblue\")\n",
    "plt.title(\"Top 5 Features - Logistic Regression\")\n",
    "plt.xlabel(\"Average Absolute Coefficient\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "# Random Forest subplot\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(x=top_rf.values, y=top_rf.index, color=\"seagreen\")\n",
    "plt.title(\"Top 5 Features - Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef207aa5-0b86-45ac-b12f-d4afe286190a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
